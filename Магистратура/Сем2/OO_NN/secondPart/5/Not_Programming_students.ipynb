{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "Not_Programming_students.ipynb",
   "provenance": [],
   "collapsed_sections": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pQu5IYHX8jId",
    "colab_type": "text",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Настройка гиперпараметров модели"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Qf5Ji2nIHixN",
    "colab_type": "code",
    "colab": {},
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "epsilon = 0.05 # Параметр эпсилон при использовании эпсилон жадной стратегии\n",
    "gamma = 0.9 # Коэффциент дисконтирования гамма\n",
    "random_seed = 10 #Random seed\n",
    "time_delay = 1 # Задержка времени при отрисовке процесса игры после обучения (секунды)"
   ],
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "nwERyO-d_orM",
    "colab_type": "code",
    "cellView": "form",
    "colab": {},
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "#@title Вывод карты\n",
    "lr_rate = 0.9 # Параметр альфа, отвечающиий за скорость обучения\n",
    "\n",
    "import gym\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "\n",
    "def generate_random_map(size, p, sd):\n",
    "    \"\"\"Generates a random valid map (one that has a path from start to goal)\n",
    "    :param size: size of each side of the grid\n",
    "    :param p: probability that a tile is frozen\n",
    "    \"\"\"\n",
    "    valid = False\n",
    "    np.random.seed(sd)\n",
    "\n",
    "    # DFS to check that it's a valid path.\n",
    "    def is_valid(res):\n",
    "        frontier, discovered = [], set()\n",
    "        frontier.append((0,0))\n",
    "        while frontier:\n",
    "            r, c = frontier.pop()\n",
    "            if not (r,c) in discovered:\n",
    "                discovered.add((r,c))\n",
    "                directions = [(1, 0), (0, 1), (-1, 0), (0, -1)]\n",
    "                for x, y in directions:\n",
    "                    r_new = r + x\n",
    "                    c_new = c + y\n",
    "                    if r_new < 0 or r_new >= size or c_new < 0 or c_new >= size:\n",
    "                        continue\n",
    "                    if res[r_new][c_new] == 'G':\n",
    "                        return True\n",
    "                    if (res[r_new][c_new] not in '#H'):\n",
    "                        frontier.append((r_new, c_new))\n",
    "        return False\n",
    "\n",
    "    while not valid:\n",
    "        p = min(1, p)\n",
    "        res = np.random.choice(['F', 'H'], (size, size), p=[p, 1-p])\n",
    "        res[0][0] = 'S'\n",
    "        res[-1][-1] = 'G'\n",
    "        valid = is_valid(res)\n",
    "    return [\"\".join(x) for x in res]\n",
    "\n",
    "\n",
    "random_map = generate_random_map(size=6, p=0.8, sd = random_seed)\n",
    "maze = random_map\n",
    "env = gym.make(\"FrozenLake-v0\", desc=random_map, is_slippery=False) #is slippery removes possibility to get in incorrect state after an action\n",
    "print(\"Ваша карта\")\n",
    "env.render()\n",
    "\n"
   ],
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ваша карта\n",
      "\n",
      "\u001B[41mS\u001B[0mFFFFF\n",
      "FFFFFH\n",
      "FFHFFF\n",
      "HFFFFF\n",
      "FFFFFF\n",
      "HFHFFG\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "nVSryhgomXjz",
    "colab_type": "code",
    "cellView": "form",
    "colab": {},
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "#@title Вывод количества побед и номера игры, когда впервые было одержано 5 побед подряд\n",
    "def choose_action(state):\n",
    "    action=0\n",
    "    if np.random.uniform(0, 1) < epsilon:\n",
    "        action = np.random.randint(0,env.action_space.n) #***\n",
    "        #action = env.action_space.sample()\n",
    "    else:\n",
    "        action = np.random.choice(np.array(np.argwhere(Q[state, :] == np.amax(Q[state, :])).flatten().tolist()))\n",
    "    return action\n",
    "\n",
    "def learn(state, state2, reward, action, done):\n",
    "    #Q-learning\n",
    "    if done:\n",
    "      Q[state, action] = Q[state, action] + lr_rate * (reward - Q[state, action])\n",
    "    else:\n",
    "      Q[state, action] = Q[state, action] + lr_rate * (reward + gamma * np.max(Q[state2, :]) - Q[state, action])\n",
    "\n",
    "\n",
    "from tqdm import tqdm\n",
    "# Inititalization\n",
    "wins_arr = [] #delete\n",
    "np.random.seed(random_seed)\n",
    "total_episodes = 10000\n",
    "max_steps = 100\n",
    "Q = np.zeros((env.observation_space.n, env.action_space.n))\n",
    "min_episode = 0 #delete\n",
    "#Main cycle\n",
    "for episode in tqdm(range(total_episodes)):\n",
    "    state = env.reset()\n",
    "    t = 0\n",
    "    while t < max_steps:\n",
    "      #delete\n",
    "        if episode > 5 and wins_arr[episode-5] == 1 and wins_arr[episode-4] == 1 and wins_arr[episode-3] == 1 and wins_arr[episode-2] == 1 and wins_arr[episode-1] == 1 and min_episode ==0:\n",
    "          min_episode = episode\n",
    "        \n",
    "        t += 1\n",
    "\n",
    "        action = choose_action(state)\n",
    "\n",
    "        state2, reward, done, info = env.step(action)\n",
    "\n",
    "        if t == max_steps:\n",
    "          done = True  \n",
    "\n",
    "        learn(state, state2, reward, action, done)\n",
    "\n",
    "        state = state2\n",
    "\n",
    "        if done and reward == 1:\n",
    "          wins_arr.append(1) #record if won\n",
    "          break\n",
    "        if done:\n",
    "          wins_arr.append(0) #record if lost\n",
    "          break\n",
    "\n",
    "#print(\"Таблица ценностей действий\")\n",
    "#print(np.round(Q,2))\n",
    "#Number of wins\n",
    "print('')\n",
    "print(\"Количество побед в серии из 10 000 игр: \", np.sum(wins_arr))\n",
    "#Number of the episode\n",
    "print(\"Пять побед подряд впервые было одержано в игре \",min_episode)"
   ],
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:03<00:00, 2863.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Количество побед в серии из 10 000 игр:  9678\n",
      "Пять побед подряд впервые было одержано в игре  153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "hgojmJYxYUoM",
    "colab_type": "code",
    "cellView": "form",
    "colab": {},
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "#@title Отдельная игра после обучения\n",
    "#Just 1 game to check if Q-table fits to win\n",
    "from IPython.display import clear_output\n",
    "import time\n",
    "\n",
    "def choose_action_one_game(state):\n",
    "    action = np.random.choice(np.array(np.argwhere(Q[state, :] == np.amax(Q[state, :])).flatten().tolist()))\n",
    "    return action\n",
    "states=[]\n",
    "t = 0\n",
    "state = env.reset()\n",
    "\n",
    "while(t<1000):\n",
    "  env.render()\n",
    "  time.sleep(time_delay)\n",
    "  clear_output(wait=True)\n",
    "  action = choose_action_one_game(state)  \n",
    "  state2, reward, done, info = env.step(action)  \n",
    "  #print(reward)\n",
    "  states.append(state)\n",
    "  state = state2\n",
    "  t += 1\n",
    "  if done and reward == 1:\n",
    "    wn=1\n",
    "  if done:\n",
    "    break\n",
    "if wn == 1:\n",
    "  print(\"!!!Победа!!!\")"
   ],
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!!!Победа!!!\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "<matplotlib.image.AxesImage at 0x181be489dc0>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#@title Построение карты маршрута\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def make_maze_pic(maze):\n",
    "  maze_pic=[]\n",
    "  for i in range(len(maze)):\n",
    "    row = []\n",
    "    for j in range(len(maze[i])):\n",
    "      if maze[i][j] == 'S':\n",
    "        row.append(0)\n",
    "      if maze[i][j] == 'F':\n",
    "        row.append(0)\n",
    "      if maze[i][j] == 'H':\n",
    "        row.append(1)\n",
    "      if maze[i][j] == 'G':\n",
    "        row.append(0)\n",
    "    maze_pic.append(row)\n",
    "  maze_pic = np.array(maze_pic)\n",
    "  return maze_pic\n",
    "  \n",
    "\n",
    "#Make maze fit to plot\n",
    "maze_pic = make_maze_pic(maze)\n",
    "nrows, ncols = maze_pic.shape\n",
    "\n",
    "#Arrays of picture elements\n",
    "rw = np.remainder(states,nrows)\n",
    "cl = np.floor_divide(states,nrows)\n",
    "rw = np.append(rw, [nrows-1])\n",
    "cl = np.append(cl,[ncols-1])\n",
    "\n",
    "#Picture plotting\n",
    "fig, ax1 = plt.subplots(1, 1, tight_layout=True)\n",
    "ax1.clear()\n",
    "ax1.set_xticks(np.arange(0.5, nrows, step=1))\n",
    "ax1.set_xticklabels([])\n",
    "ax1.set_yticks(np.arange(0.5, ncols, step=1))\n",
    "ax1.set_yticklabels([])\n",
    "ax1.grid(True)\n",
    "ax1.plot([0],[0], \"gs\", markersize=40)  # start is a big green square\n",
    "ax1.text(0, 0.2,\"Start\", ha=\"center\", va=\"center\", color=\"white\", fontsize=12) #Start text\n",
    "ax1.plot([nrows-1],[ncols-1], \"rs\", markersize=40)  # exit is a big red square\n",
    "ax1.text(nrows-1, ncols-1+0.2,\"Finish\", ha=\"center\", va=\"center\", color=\"white\", fontsize=12) #Exit text\n",
    "ax1.plot(rw,cl, ls = '-', color = 'blue') #Blue lines path\n",
    "ax1.plot(rw,cl, \"bo\")  # Blue dots visited cells\n",
    "ax1.imshow(maze_pic, cmap=\"binary\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ]
}