{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Vd_ST0GfO97y",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Информационный поиск\n",
    "\n",
    "Скачиваем классический набор данных -- набор текстов об аэронавтике CRANFIELD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6989,
     "status": "ok",
     "timestamp": 1586443376578,
     "user": {
      "displayName": "Дмитрий Волчек",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgN8jjHr8b6AlqmkI_BBSJH_qXpcmh3mgxKpBXd=s64",
      "userId": "12396512946067001179"
     },
     "user_tz": -180
    },
    "id": "AHflLH2APAHK",
    "outputId": "2a1dad1c-2e1a-4bdc-91a2-f6befe15be64",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\"wget\" ­Ґ пў«пҐвбп ў­гваҐ­­Ґ© Ё«Ё ў­Ґи­Ґ©\n",
      "Є®¬ ­¤®©, ЁбЇ®«­пҐ¬®© Їа®Ја ¬¬®© Ё«Ё Ї ЄҐв­л¬ д ©«®¬.\n",
      "tar: Error opening archive: Failed to open 'cran.tar.gz'\n",
      "\"rm\" ­Ґ пў«пҐвбп ў­гваҐ­­Ґ© Ё«Ё ў­Ґи­Ґ©\n",
      "Є®¬ ­¤®©, ЁбЇ®«­пҐ¬®© Їа®Ја ¬¬®© Ё«Ё Ї ЄҐв­л¬ д ©«®¬.\n"
     ]
    }
   ],
   "source": [
    "! wget -q http://ir.dcs.gla.ac.uk/resources/test_collections/cran/cran.tar.gz\n",
    "! tar -xvf cran.tar.gz\n",
    "! rm cran.tar.gz*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zYuND83cPR5D",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Берём только сами запросы (это будут наши документы)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4553,
     "status": "ok",
     "timestamp": 1586443381958,
     "user": {
      "displayName": "Дмитрий Волчек",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgN8jjHr8b6AlqmkI_BBSJH_qXpcmh3mgxKpBXd=s64",
      "userId": "12396512946067001179"
     },
     "user_tz": -180
    },
    "id": "6owW-L7zhJws",
    "outputId": "5d1a9a46-5e0e-4fce-bab6-93b3f3dadf94",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\"grep\" ­Ґ пў«пҐвбп ў­гваҐ­­Ґ© Ё«Ё ў­Ґи­Ґ©\n",
      "Є®¬ ­¤®©, ЁбЇ®«­пҐ¬®© Їа®Ја ¬¬®© Ё«Ё Ї ЄҐв­л¬ д ©«®¬.\n",
      "\"head\" ­Ґ пў«пҐвбп ў­гваҐ­­Ґ© Ё«Ё ў­Ґи­Ґ©\n",
      "Є®¬ ­¤®©, ЁбЇ®«­пҐ¬®© Їа®Ја ¬¬®© Ё«Ё Ї ЄҐв­л¬ д ©«®¬.\n"
     ]
    }
   ],
   "source": [
    "! grep -v \"^\\.\" cran.qry > just.qry\n",
    "! head -3 just.qry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8ZbUb6FmQxr1",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Объединяем многострочные в один"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1217,
     "status": "ok",
     "timestamp": 1586443394212,
     "user": {
      "displayName": "Дмитрий Волчек",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgN8jjHr8b6AlqmkI_BBSJH_qXpcmh3mgxKpBXd=s64",
      "userId": "12396512946067001179"
     },
     "user_tz": -180
    },
    "id": "SBaV3xeQiUam",
    "outputId": "68bf7ac9-a2f8-43f9-d165-f6f0702c7620",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "['']"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_query_data = [line.strip() for line in open(\"just.qry\", \"r\").readlines()]\n",
    "query_data = [\"\"]\n",
    "\n",
    "for query_part in raw_query_data:\n",
    "  query_data[-1] += query_part + \" \"\n",
    "  if query_part.endswith(\".\"):\n",
    "    query_data.append(\"\")\n",
    "\n",
    "query_data[:2] #Выведем пару документов для примера"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nLFq_6lBki3S",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Составим запросы к нашим документам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "h3sgHjWkjjR1",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "QUERIES = ['delta wings']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hQMdH0HSkoJg",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Boolean retrieval\n",
    "Представим каждый документ как \"битовую маску\": вектор размером со словарь, в котором на каждой позиции единица, если в документе есть соответсвующий терм, и ноль, если терма нет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lhrI18rZSLLz",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "# в разных версиях ответы могут отличаться, поэтому важно иметь одну и ту же\n",
    "! pip install -q scikit-learn==0.22.2.post1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 912,
     "status": "ok",
     "timestamp": 1586443705365,
     "user": {
      "displayName": "Дмитрий Волчек",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgN8jjHr8b6AlqmkI_BBSJH_qXpcmh3mgxKpBXd=s64",
      "userId": "12396512946067001179"
     },
     "user_tz": -180
    },
    "id": "DbTOdsHIknD0",
    "outputId": "79421614-b319-472d-a52c-c082ffb7e70e",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "empty vocabulary; perhaps the documents only contain stop words",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[1;32mC:\\Users\\D899~1\\AppData\\Local\\Temp/ipykernel_12388/1471422087.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[0mencoder\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mCountVectorizer\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mbinary\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mTrue\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 4\u001B[1;33m \u001B[0mencoded_data\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mencoder\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfit_transform\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mquery_data\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      5\u001B[0m \u001B[0mencoded_queries\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mencoder\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtransform\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mQUERIES\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      6\u001B[0m \u001B[0mlist\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mencoder\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mvocabulary_\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;36m3\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001B[0m in \u001B[0;36mfit_transform\u001B[1;34m(self, raw_documents, y)\u001B[0m\n\u001B[0;32m   1200\u001B[0m         \u001B[0mmax_features\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmax_features\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1201\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1202\u001B[1;33m         vocabulary, X = self._count_vocab(raw_documents,\n\u001B[0m\u001B[0;32m   1203\u001B[0m                                           self.fixed_vocabulary_)\n\u001B[0;32m   1204\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001B[0m in \u001B[0;36m_count_vocab\u001B[1;34m(self, raw_documents, fixed_vocab)\u001B[0m\n\u001B[0;32m   1131\u001B[0m             \u001B[0mvocabulary\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mdict\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mvocabulary\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1132\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[0mvocabulary\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1133\u001B[1;33m                 raise ValueError(\"empty vocabulary; perhaps the documents only\"\n\u001B[0m\u001B[0;32m   1134\u001B[0m                                  \" contain stop words\")\n\u001B[0;32m   1135\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mValueError\u001B[0m: empty vocabulary; perhaps the documents only contain stop words"
     ]
    }
   ],
   "source": [
    "from  sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "encoder = CountVectorizer(binary=True)\n",
    "encoded_data = encoder.fit_transform(query_data)\n",
    "encoded_queries = encoder.transform(QUERIES)\n",
    "list(encoder.vocabulary_)[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oUdwKDKSTjdD",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Посмотрим на представление первого предложения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 272
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 805,
     "status": "ok",
     "timestamp": 1586443719795,
     "user": {
      "displayName": "Дмитрий Волчек",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgN8jjHr8b6AlqmkI_BBSJH_qXpcmh3mgxKpBXd=s64",
      "userId": "12396512946067001179"
     },
     "user_tz": -180
    },
    "id": "oXEmXErylJdX",
    "outputId": "d8f41827-aa26-4587-a774-7385bd15cf13",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'CountVectorizer' object has no attribute 'vocabulary_'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "\u001B[1;32mC:\\Users\\D899~1\\AppData\\Local\\Temp/ipykernel_12388/1322307227.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[0mid2term\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m{\u001B[0m\u001B[0midx\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mterm\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0mterm\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0midx\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mencoder\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mvocabulary_\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mitems\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m}\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      2\u001B[0m \u001B[0mnon_zero_values_ids\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mencoded_data\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mnonzero\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[0mterms\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[0mid2term\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0midx\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0midx\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mnon_zero_values_ids\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[0mterms\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mAttributeError\u001B[0m: 'CountVectorizer' object has no attribute 'vocabulary_'"
     ]
    }
   ],
   "source": [
    "id2term = {idx: term for term, idx in encoder.vocabulary_.items()}\n",
    "non_zero_values_ids = encoded_data[0].nonzero()[1]\n",
    "\n",
    "terms = [id2term[idx] for idx in non_zero_values_ids]\n",
    "terms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "l8wdS9XiVwb2",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Всё так.\n",
    "\n",
    "## Задание 0\n",
    "\n",
    "Теперь для каждого из данных запросов `QUERIES` найдём ближайший для него документ из `query_data` по сходству Жаккара. Есть более эффективные способы это сделать, но вам требуется реализовать расстояние Жаккара и далее применить его к нашим данным."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "u31WuBYAUWt2",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "\n",
    "def jaccard_sim(vector_a: np.array, vector_b: np.array) -> float:\n",
    "  \"\"\"\n",
    "    Сходство или коэффициент Жаккара: отношение мощности пересечения\n",
    "    к мощности объединения\n",
    "  \"\"\"\n",
    "  # ваш код здесь\n",
    "  \n",
    "  return\n",
    "#Проверка, что функция работает правильно\n",
    "assert jaccard_sim(np.array([1, 0, 1, 0, 1]), np.array([0, 1, 1, 1, 1])) == 0.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Здесь документы представлены так же, как строки в матрице термов-документов. Каждая ячейка вектора отвечает за наличие/отсутствие конкретного элемента (например, слова-терма, когда у нас в словаре всего 5 слов). В первом случае их три, во втором — четыре. Объединение — все пять возможных элементов. Пересечение — два. Отсюда и 0.4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dYfQksWrOR1G",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Задание 1\n",
    "Теперь с помощью кода ниже вычислите для каждого запроса самые близкие документы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 207
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 830,
     "status": "ok",
     "timestamp": 1586443823267,
     "user": {
      "displayName": "Дмитрий Волчек",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgN8jjHr8b6AlqmkI_BBSJH_qXpcmh3mgxKpBXd=s64",
      "userId": "12396512946067001179"
     },
     "user_tz": -180
    },
    "id": "4okpFpA6OAQs",
    "outputId": "f08c69ca-de42-480a-c9a0-044135703a28",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: theory of bending\n",
      "FOUND:\n",
      "    42\t0.20\twhat are the details of the rigorous kinetic theory of gases . \n",
      "    43\t0.20\t(chapman-enskog theory) . \n",
      "    146\t0.19\tdoes a membrane theory exist by which the behaviour of pressurized membrane cylinders in bending can be predicted . \n",
      "Q: aeroelastic effects\n",
      "FOUND:\n",
      "    196\t0.14\tthe problem of similarity for representative investigation of aeroelastic effects in a flow with the absence of heating effects . \n",
      "    204\t0.12\tdo viscous effects seriously modify pressure distributions . \n",
      "    114\t0.12\tis the problem of similarity for representative investigations of aeroelastic effects in heated flow as intractable as previous investigations imply . \n"
     ]
    }
   ],
   "source": [
    "for q_id, query in enumerate(encoded_queries):\n",
    "  # приводим к нужному типу\n",
    "  query = query.todense().A1\n",
    "  docs = [doc.todense().A1 for doc in encoded_data]\n",
    "  # вычисляем коэфф. Жаккара\n",
    "  id2doc2similarity = [(doc_id, doc, jaccard_sim(query, doc)) for doc_id, doc in enumerate(docs)]\n",
    "  # сортируем по нему\n",
    "  closest = sorted(id2doc2similarity, key=lambda x: x[2], reverse=True)\n",
    "  \n",
    "  print(\"Q: %s\\nFOUND:\" % QUERIES[q_id])\n",
    "  # выводим по 3 наиболее близких документа для каждого запроса\n",
    "  for closest_id, _, sim in closest[:3]:\n",
    "    print(\"    %d\\t%.2f\\t%s\" %(closest_id, sim, query_data[closest_id]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "A1Fh8RdvOrAD",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Видим, что кое-где просачиваются  тексты, которых с запросами объединяют малозначительные термы, но при этом коэффициент Жаккара -- наша функция ранжирования! -- высок.\n",
    "\n",
    "# VSM\n",
    "\n",
    "Попробуем теперь сделать то же, но с tf-idf и косинусным расстоянием. Мы сделаем всё опять \"руками\", но \"в реальной жизни\" лучше использоватьесть эффективные реализации cosine distance, например, из библиотеки scipy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 925,
     "status": "ok",
     "timestamp": 1586443962126,
     "user": {
      "displayName": "Дмитрий Волчек",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgN8jjHr8b6AlqmkI_BBSJH_qXpcmh3mgxKpBXd=s64",
      "userId": "12396512946067001179"
     },
     "user_tz": -180
    },
    "id": "DmpKMI08E2iO",
    "outputId": "957b4013-7b8f-431c-e6d1-697075fb207f",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['what', 'similarity', 'laws']"
      ]
     },
     "execution_count": 24,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from  sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Совет: обязательно разберитесь с тем, какие возможности\n",
    "# предоставляет tf-idf vectorizer, какие параметры за что отвечают\n",
    "\n",
    "tfidf_encoder = TfidfVectorizer()\n",
    "tfidf_encoded_data = tfidf_encoder.fit_transform(query_data)\n",
    "tfidf_encoded_queries = tfidf_encoder.transform(QUERIES)\n",
    "\n",
    "list(tfidf_encoder.vocabulary_)[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hHTzIjfNRHj2",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Задание 2\n",
    "Реализовать косинусное расстояние"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UCfgR6xEPeDn",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "\n",
    "def cosine_distance(vector_a: np.array, vector_b: np.array) -> float:\n",
    "  \"\"\"\n",
    "    Косинусное расстояние: единица минус отношение скалярного произведения\n",
    "    на произведение L2-норм (подсказка: в numpy такие нормы есть)\n",
    "  \"\"\"\n",
    "  # ваш код здесь\n",
    "\n",
    "  return  \n",
    "#Проверка, что функция работает правильно\n",
    "assert cosine_distance(np.array([1, 0, 1, 1, 1]), np.array([0, 0, 1, 0, 0])) == 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vJHsaHoORlEC",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "\n",
    "Теперь вычислим ближайшие по косинусному расстоянию между векторными представлениями документов и запросов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 275
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 742,
     "status": "ok",
     "timestamp": 1586444002708,
     "user": {
      "displayName": "Дмитрий Волчек",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgN8jjHr8b6AlqmkI_BBSJH_qXpcmh3mgxKpBXd=s64",
      "userId": "12396512946067001179"
     },
     "user_tz": -180
    },
    "id": "fIZJRBKQQR1G",
    "outputId": "6515e3a4-b4eb-4943-f1e0-26f9fec648d3",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: theory of bending\n",
      "FOUND:\n",
      "    145\t0.65\twhat are the best experimental data and classical small deflection theory analyses available for pressurized cylinders in bending . \n",
      "    146\t0.66\tdoes a membrane theory exist by which the behaviour of pressurized membrane cylinders in bending can be predicted . \n",
      "    111\t0.66\thas the solution of the clamped plate problem,  in the classical theory of bending,  been reduced to two successive membrane boundary value problems . \n",
      "Q: aeroelastic effects\n",
      "FOUND:\n",
      "    196\t0.51\tthe problem of similarity for representative investigation of aeroelastic effects in a flow with the absence of heating effects . \n",
      "    114\t0.70\tis the problem of similarity for representative investigations of aeroelastic effects in heated flow as intractable as previous investigations imply . \n",
      "    1\t0.74\twhat are the structural and aeroelastic problems associated with flight of high speed aircraft . \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "for q_id, query in enumerate(tfidf_encoded_queries):\n",
    "  \n",
    "  # приводим к нужному типу\n",
    "  query = query.todense().A1\n",
    "  docs = [doc.todense().A1 for doc in tfidf_encoded_data]\n",
    "  # Косинусное расстояние\n",
    "  id2doc2similarity = [(doc_id, doc, cosine_distance(query, doc)) \\\n",
    "                       for doc_id, doc in enumerate(docs)]\n",
    "  # сортируем по нему\n",
    "  closest = sorted(id2doc2similarity, key=lambda x: x[2], reverse=False)\n",
    "  \n",
    "  print(\"Q: %s\\nFOUND:\" % QUERIES[q_id])\n",
    "  \n",
    "  for closest_id, _, sim in closest[:3]:\n",
    "    print(\"    %d\\t%.2f\\t%s\" %(closest_id, sim, query_data[closest_id]))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "5_2_Programming_students.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}